{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq8NmenGsjiK",
        "outputId": "ba5a1b05-d934-4516-cfe0-b5e9a21f0e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug  3 17:55:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a0ZlUPdxlsK9"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from torch import Tensor\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from collections import OrderedDict\n",
        "from torch import Tensor\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Subset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import random\n",
        "from google.colab import files\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "import sklearn\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "from torch.autograd import Variable\n",
        "import skimage.segmentation\n",
        "import skimage.io\n",
        "import skimage \n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import skimage.segmentation\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "import skimage.segmentation\n",
        "from skimage import feature\n",
        "from skimage import filters\n",
        "import copy\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Histopathology_Datasets/Nuclei_Datasets/Nuclei_Dataset1_Segmentation_Regression'"
      ],
      "metadata": {
        "id": "NpQV4fDX7UDX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=os.listdir('/content/drive/MyDrive/Histopathology_Datasets/Nuclei_Datasets/Nuclei_Dataset1_Segmentation_Regression')\n",
        "l.sort()"
      ],
      "metadata": {
        "id": "alD_e0J4zsf0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image=[]\n",
        "train_label=[]\n",
        "test_image=[]\n",
        "test_label=[]\n",
        "for i in range(11):\n",
        "  image_path=path+'/'+l[i+12]\n",
        "  image_path=glob.glob(image_path+'*/**.png')\n",
        "  image_path.sort()\n",
        "  train_image_path,test_image_path=sklearn.model_selection.train_test_split(image_path,test_size=0.2,random_state=1154)\n",
        "  train_image.extend(train_image_path)\n",
        "  test_image.extend(test_image_path)\n",
        "\n",
        "  label_path=path+'/'+l[i+1]\n",
        "  label_path=glob.glob(label_path+'*/**.png')\n",
        "  label_path.sort()\n",
        "  train_label_path,test_label_path=sklearn.model_selection.train_test_split(label_path,test_size=0.2,random_state=1154)\n",
        "  train_label.extend(train_label_path)\n",
        "  test_label.extend(test_label_path)"
      ],
      "metadata": {
        "id": "GyOCoTDCz48W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTsWXiFuZuku"
      },
      "source": [
        "def extract_patches_2d(img,patch_shape,step=[1.0,1.0],batch_first=False):\n",
        "    patch_H, patch_W = patch_shape[0], patch_shape[1]\n",
        "    if(img.size(2)<patch_H):\n",
        "        num_padded_H_Top = (patch_H - img.size(2))//2\n",
        "        num_padded_H_Bottom = patch_H - img.size(2) - num_padded_H_Top\n",
        "        padding_H = nn.ConstantPad2d((0,0,num_padded_H_Top,num_padded_H_Bottom),0)\n",
        "        img = padding_H(img)\n",
        "    if(img.size(3)<patch_W):\n",
        "        num_padded_W_Left = (patch_W - img.size(3))//2\n",
        "        num_padded_W_Right = patch_W - img.size(3) - num_padded_W_Left\n",
        "        padding_W = nn.ConstantPad2d((num_padded_W_Left,num_padded_W_Right,0,0),0)\n",
        "        img = padding_W(img)\n",
        "    step_int = [0,0]\n",
        "    step_int[0] = int(patch_H*step[0]) if(isinstance(step[0], float)) else step[0]\n",
        "    step_int[1] = int(patch_W*step[1]) if(isinstance(step[1], float)) else step[1]\n",
        "    patches_fold_H = img.unfold(2, patch_H, step_int[0])\n",
        "    if((img.size(2) - patch_H) % step_int[0] != 0):\n",
        "        patches_fold_H = torch.cat((patches_fold_H,img[:,:,-patch_H:,].permute(0,1,3,2).unsqueeze(2)),dim=2)\n",
        "    patches_fold_HW = patches_fold_H.unfold(3, patch_W, step_int[1])   \n",
        "    if((img.size(3) - patch_W) % step_int[1] != 0):\n",
        "        patches_fold_HW = torch.cat((patches_fold_HW,patches_fold_H[:,:,:,-patch_W:,:].permute(0,1,2,4,3).unsqueeze(3)),dim=3)\n",
        "    patches = patches_fold_HW.permute(2,3,0,1,4,5)\n",
        "    patches = patches.reshape(-1,img.size(0),img.size(1),patch_H,patch_W)\n",
        "    if(batch_first):\n",
        "        patches = patches.permute(1,0,2,3,4)\n",
        "    return patches\n",
        "\n",
        "def reconstruct_from_patches_2d(patches,img_shape,step=[1.0,1.0],batch_first=False):\n",
        "    if(batch_first):\n",
        "        patches = patches.permute(1,0,2,3,4)\n",
        "    patch_H, patch_W = patches.size(3), patches.size(4)\n",
        "    img_size = (patches.size(1), patches.size(2),max(img_shape[0], patch_H), max(img_shape[1], patch_W))\n",
        "    step_int = [0,0]\n",
        "    step_int[0] = int(patch_H*step[0]) if(isinstance(step[0], float)) else step[0]\n",
        "    step_int[1] = int(patch_W*step[1]) if(isinstance(step[1], float)) else step[1]\n",
        "    nrow, ncol = 1 + (img_size[-2] - patch_H)//step_int[0], 1 + (img_size[-1] - patch_W)//step_int[1]\n",
        "    r_nrow = nrow + 1 if((img_size[2] - patch_H) % step_int[0] != 0) else nrow\n",
        "    r_ncol = ncol + 1 if((img_size[3] - patch_W) % step_int[1] != 0) else ncol\n",
        "    patches = patches.reshape(r_nrow,r_ncol,img_size[0],img_size[1],patch_H,patch_W)\n",
        "    img = torch.zeros(img_size, device = patches.device)\n",
        "    overlap_counter = torch.zeros(img_size, device = patches.device)\n",
        "    for i in range(nrow):\n",
        "        for j in range(ncol):\n",
        "            img[:,:,i*step_int[0]:i*step_int[0]+patch_H,j*step_int[1]:j*step_int[1]+patch_W] += patches[i,j,]\n",
        "            overlap_counter[:,:,i*step_int[0]:i*step_int[0]+patch_H,j*step_int[1]:j*step_int[1]+patch_W] += 1\n",
        "    if((img_size[2] - patch_H) % step_int[0] != 0):\n",
        "        for j in range(ncol):\n",
        "            img[:,:,-patch_H:,j*step_int[1]:j*step_int[1]+patch_W] += patches[-1,j,]\n",
        "            overlap_counter[:,:,-patch_H:,j*step_int[1]:j*step_int[1]+patch_W] += 1\n",
        "    if((img_size[3] - patch_W) % step_int[1] != 0):\n",
        "        for i in range(nrow):\n",
        "            img[:,:,i*step_int[0]:i*step_int[0]+patch_H,-patch_W:] += patches[i,-1,]\n",
        "            overlap_counter[:,:,i*step_int[0]:i*step_int[0]+patch_H,-patch_W:] += 1\n",
        "    if((img_size[2] - patch_H) % step_int[0] != 0 and (img_size[3] - patch_W) % step_int[1] != 0):\n",
        "        img[:,:,-patch_H:,-patch_W:] += patches[-1,-1,]\n",
        "        overlap_counter[:,:,-patch_H:,-patch_W:] += 1\n",
        "    img /= overlap_counter\n",
        "    if(img_shape[0]<patch_H):\n",
        "        num_padded_H_Top = (patch_H - img_shape[0])//2\n",
        "        num_padded_H_Bottom = patch_H - img_shape[0] - num_padded_H_Top\n",
        "        img = img[:,:,num_padded_H_Top:-num_padded_H_Bottom,]\n",
        "    if(img_shape[1]<patch_W):\n",
        "        num_padded_W_Left = (patch_W - img_shape[1])//2\n",
        "        num_padded_W_Right = patch_W - img_shape[1] - num_padded_W_Left\n",
        "        img = img[:,:,:,num_padded_W_Left:-num_padded_W_Right]\n",
        "    return img\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_generator(image_path,labels_path,im_path,label_path):\n",
        "  for i in range(len(image_path)):\n",
        "    image=imageio.imread(image_path[i])\n",
        "    label=imageio.imread(labels_path[i])\n",
        "    image=torch.from_numpy(image[:,:,0:3])\n",
        "    label=torch.from_numpy(label)\n",
        "    image=image.permute(2,0,1).unsqueeze(0)\n",
        "    label=label.unsqueeze(0).unsqueeze(0)\n",
        "    images=extract_patches_2d(image,(128,128),step=[1.0,1.0],batch_first=True)\n",
        "    labels=extract_patches_2d(label,(128,128),step=[1.0,1.0],batch_first=True)\n",
        "    for j in range(images.shape[1]):\n",
        "      a=images[0,j,:,:,:].permute(1,2,0)\n",
        "      b=labels[0,j,:,:,:].permute(1,2,0)\n",
        "      a=np.array(a).astype('uint8')\n",
        "      b=np.array(b).astype('uint8')\n",
        "      img_pth=str(i) + '_' + str(j) + '_' + 'image.png'\n",
        "      lbl_pth=str(i) + '_' + str(j) + '_' + 'label.png'\n",
        "      final_image_path=os.path.join(im_path,img_pth)\n",
        "      final_label_path=os.path.join(label_path,lbl_pth)\n",
        "      cv2.imwrite(final_image_path,a)\n",
        "      cv2.imwrite(final_label_path,b)"
      ],
      "metadata": {
        "id": "invYJ-sTm4sS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir Train_images\n",
        "%mkdir Train_labels\n",
        "\n",
        "%mkdir Test_images\n",
        "%mkdir Test_labels\n",
        "\n",
        "image_generator(train_image,train_label,'/content/Train_images', '/content/Train_labels')\n",
        "image_generator(test_image,test_label,'/content/Test_images', '/content/Test_labels')"
      ],
      "metadata": {
        "id": "NZKehsS3NIWB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=imageio.imread('/content/Test_labels/12_0_label.png')"
      ],
      "metadata": {
        "id": "AODkvMu0mcWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeStaining(img, Io=240, alpha=1, beta=0.15):\n",
        "    ''' Normalize staining appearence of H&E stained images\n",
        "    \n",
        "    Example use:\n",
        "        see test.py\n",
        "        \n",
        "    Input:\n",
        "        I: RGB input image\n",
        "        Io: (optional) transmitted light intensity\n",
        "        \n",
        "    Output:\n",
        "        Inorm: normalized image\n",
        "        H: hematoxylin image\n",
        "        E: eosin image\n",
        "    \n",
        "    Reference: \n",
        "        A method for normalizing histology slides for quantitative analysis. M.\n",
        "        Macenko et al., ISBI 2009\n",
        "    '''\n",
        "             \n",
        "    HERef = np.array([[0.5626, 0.2159],\n",
        "                      [0.7201, 0.8012],\n",
        "                      [0.4062, 0.5581]])\n",
        "        \n",
        "    maxCRef = np.array([1.9705, 1.0308])\n",
        "    \n",
        "    # define height and width of image\n",
        "    h, w, c = img.shape\n",
        "    \n",
        "    # reshape image\n",
        "    img = img.reshape((-1,3))\n",
        "\n",
        "    # calculate optical density\n",
        "    OD = -np.log((img.astype(np.float32)+1)/Io)\n",
        "    \n",
        "    # remove transparent pixels\n",
        "    ODhat = OD[~np.any(OD<beta, axis=1)]\n",
        "        \n",
        "    # compute eigenvectors\n",
        "    eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
        "    \n",
        "    #eigvecs *= -1\n",
        "    \n",
        "    #project on the plane spanned by the eigenvectors corresponding to the two \n",
        "    # largest eigenvalues    \n",
        "    That = ODhat.dot(eigvecs[:,1:3])\n",
        "    \n",
        "    phi = np.arctan2(That[:,1],That[:,0])\n",
        "    \n",
        "    minPhi = np.percentile(phi, alpha)\n",
        "    maxPhi = np.percentile(phi, 100-alpha)\n",
        "    \n",
        "    vMin = eigvecs[:,1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
        "    vMax = eigvecs[:,1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
        "    \n",
        "    # a heuristic to make the vector corresponding to hematoxylin first and the \n",
        "    # one corresponding to eosin second\n",
        "    if vMin[0] > vMax[0]:\n",
        "        HE = np.array((vMin[:,0], vMax[:,0])).T\n",
        "    else:\n",
        "        HE = np.array((vMax[:,0], vMin[:,0])).T\n",
        "    \n",
        "    # rows correspond to channels (RGB), columns to OD values\n",
        "    Y = np.reshape(OD, (-1, 3)).T\n",
        "    \n",
        "    # determine concentrations of the individual stains\n",
        "    C = np.linalg.lstsq(HE,Y, rcond=None)[0]\n",
        "    \n",
        "    # normalize stain concentrations\n",
        "    maxC = np.array([np.percentile(C[0,:], 99), np.percentile(C[1,:],99)])\n",
        "    tmp = np.divide(maxC,maxCRef)\n",
        "    C2 = np.divide(C,tmp[:, np.newaxis])\n",
        "    \n",
        "    # recreate the image using reference mixing matrix\n",
        "    Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))\n",
        "    Inorm[Inorm>255] = 254\n",
        "    Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)  \n",
        "    \n",
        "    # unmix hematoxylin and eosin\n",
        "    H = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,0], axis=1).dot(np.expand_dims(C2[0,:], axis=0))))\n",
        "    H[H>255] = 254\n",
        "    H = np.reshape(H.T, (h, w, 3)).astype(np.uint8)\n",
        "    \n",
        "    E = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,1], axis=1).dot(np.expand_dims(C2[1,:], axis=0))))\n",
        "    E[E>255] = 254\n",
        "    E = np.reshape(E.T, (h, w, 3)).astype(np.uint8)\n",
        "\n",
        "    return Inorm, H, E"
      ],
      "metadata": {
        "id": "M9j4hoSgN2Ip"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TNBC_train(Dataset):\n",
        "  def __init__(self):\n",
        "    self.image_path=glob.glob('/content/Train_images*/**.png')\n",
        "    self.image_path.sort()\n",
        "    self.labels=glob.glob('/content/Train_labels*/**.png')\n",
        "    self.labels.sort()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)    \n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    image=imageio.imread(self.image_path[idx])\n",
        "    if idx not in [81,85,86,90,121,250,410,414,419,420,430,431]:\n",
        "      image,H,E=normalizeStaining(image)  \n",
        "    label=imageio.imread(self.labels[idx])\n",
        "    bound=skimage.segmentation.find_boundaries(label, mode='inner')\n",
        "    bound=bound*1.0\n",
        "    label=(label>0)*1.0\n",
        "\n",
        "    image=torch.from_numpy(image/255.0).permute(2,1,0) \n",
        "    label=torch.from_numpy(label).unsqueeze(0)\n",
        "    bound=torch.from_numpy(bound).unsqueeze(0)\n",
        "    label=torch.rot90(label, 1, [1,2])\n",
        "    label=torch.flip(label,[0,1])\n",
        "    bound=torch.rot90(bound, 1, [1,2])\n",
        "    bound=torch.flip(bound,[0,1])    \n",
        "    return image, torch.cat((label,bound),0)    "
      ],
      "metadata": {
        "id": "wm546kOcnHLX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TNBC_test(Dataset):\n",
        "  def __init__(self):\n",
        "    self.image_path=glob.glob('/content/Test_images*/**.png')\n",
        "    self.image_path.sort()\n",
        "    self.labels=glob.glob('/content/Test_labels*/**.png')\n",
        "    self.labels.sort()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)    \n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    image=imageio.imread(self.image_path[idx])\n",
        "    if idx not in [46]:\n",
        "      image,H,E=normalizeStaining(image)  \n",
        "    label=imageio.imread(self.labels[idx])\n",
        "    bound=skimage.segmentation.find_boundaries(label, mode='inner')\n",
        "    bound=bound*1.0    \n",
        "    label=(label>0)*1.0\n",
        "\n",
        "    image=torch.from_numpy(image/255.0).permute(2,1,0) \n",
        "    label=torch.from_numpy(label).unsqueeze(0)\n",
        "    bound=torch.from_numpy(bound).unsqueeze(0)\n",
        "    label=torch.rot90(label, 1, [1,2])\n",
        "    label=torch.flip(label,[0,1])\n",
        "    bound=torch.rot90(bound, 1, [1,2])\n",
        "    bound=torch.flip(bound,[0,1])    \n",
        "    return image, torch.cat((label,bound),0)   "
      ],
      "metadata": {
        "id": "NAm_UGxEnJUG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=TNBC_train()\n",
        "test_ds=TNBC_test()\n",
        "train_dl=DataLoader(train_ds,batch_size=16,num_workers=2)\n",
        "test_dl=DataLoader(test_ds,batch_size=16,num_workers=2)"
      ],
      "metadata": {
        "id": "DOFig864UxCr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3Z_d-HBHQUN"
      },
      "outputs": [],
      "source": [
        "class Upsample(nn.Module):\n",
        "    \"\"\" nn.Upsample is deprecated \"\"\"\n",
        " \n",
        "    def __init__(self, scale_factor, mode=\"bilinear\"):\n",
        "        super(Upsample, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode, align_corners=True, recompute_scale_factor=True)\n",
        "        return x    \n",
        "        \n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        " \n",
        " \n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5JIzfLX69t"
      },
      "outputs": [],
      "source": [
        "class bn_conv(nn.Module):\n",
        "    def __init__(self,num_init_features,output_channels,dilation=1):\n",
        "        super(bn_conv,self).__init__()\n",
        "        self.features = nn.Sequential(OrderedDict([ \n",
        "            ('conv0', nn.Conv2d(num_init_features,output_channels,kernel_size=3, stride=1,\n",
        "                                padding=dilation, bias=False,dilation=dilation)), \n",
        "            ('norm0', nn.BatchNorm2d(output_channels)),\n",
        "            ('relu0', nn.ReLU(inplace=True))          \n",
        "    \n",
        "        ]))\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WakFrT8pP95R"
      },
      "outputs": [],
      "source": [
        "class bn_conv2(nn.Module):\n",
        "    def __init__(self, initial_channels,output_channels,dilation=1):\n",
        "        super(bn_conv2,self).__init__()\n",
        "        self.conv1=bn_conv(initial_channels,output_channels,dilation)\n",
        "        self.conv2=bn_conv(output_channels,output_channels,dilation)\n",
        "    def forward(self, x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.conv2(x)\n",
        "        return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQh0hOaCYOHW"
      },
      "outputs": [],
      "source": [
        "class Spatial_Attn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Spatial_Attn,self).__init__()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x1=torch.mean(x,1,keepdim=True)\n",
        "    x2,_=torch.max(x,1,keepdim=True)  \n",
        "    x_out = x*torch.sigmoid(x1) + x*torch.sigmoid(x2)\n",
        "    return x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0q-Bk0EO5nQ"
      },
      "outputs": [],
      "source": [
        "class Channel_Attn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Channel_Attn,self).__init__()\n",
        "    self.gap=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.gmp=nn.AdaptiveMaxPool2d((1,1))\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x1=self.gap(x) \n",
        "    x2=self.gmp(x)\n",
        "    x_out = x*torch.sigmoid(x1) + x*torch.sigmoid(x2)\n",
        "    return x_out  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmifeBZBZH1p"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self,input_features):\n",
        "    super(Attention,self).__init__()\n",
        "    self.sa=Spatial_Attn()\n",
        "    self.ca=Channel_Attn()\n",
        "    self.conv=conv3x3(2*input_features,input_features)\n",
        "    self.bn=nn.BatchNorm2d(input_features)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x1=self.sa(x)\n",
        "    x2=self.ca(x)\n",
        "    x_attn=torch.cat((x1,x2),1)\n",
        "    x_attn=self.bn(self.conv(x_attn))\n",
        "    x_attn=x+x_attn\n",
        "    x_attn=x*torch.sigmoid(x_attn)\n",
        "    return x_attn    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwycDmWba03G"
      },
      "outputs": [],
      "source": [
        "class enc_sup(nn.Module):\n",
        "  def __init__(self,input_features,upsample_factor=1):\n",
        "    super(enc_sup,self).__init__()\n",
        "    self.conv1=nn.Conv2d(input_features,64,kernel_size=1)\n",
        "    self.upsample=Upsample(upsample_factor)\n",
        "    self.conv2=nn.Conv2d(64,64,kernel_size=1)\n",
        "    self.out=nn.Conv2d(64,2,kernel_size=1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.upsample(x)\n",
        "    x=self.conv2(x)\n",
        "    x_out=self.out(x)\n",
        "    return torch.sigmoid(x_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNA_rfXQcXPk"
      },
      "outputs": [],
      "source": [
        "class dec_sup(nn.Module):\n",
        "  def __init__(self,input_features):\n",
        "    super(dec_sup,self).__init__()\n",
        "    self.conv1=bn_conv(input_features,64)\n",
        "    self.conv2=nn.Conv2d(64,64,kernel_size=1)\n",
        "    self.out=nn.Conv2d(64,2,kernel_size=1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.conv2(x)\n",
        "    x_out=self.out(x)\n",
        "    return torch.sigmoid(x_out)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLEFgvSedYR8"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        " \n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample = True,\n",
        "        dilation: list = [],\n",
        "        upsample_factor: int = 1        \n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride=1 ,dilation=dilation[0])\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes,stride=1,dilation=dilation[1])\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        # self.conv3 = conv3x3(planes, planes,stride=1,dilation=dilation[2])\n",
        "        # self.bn3 = norm_layer(planes)        \n",
        "\n",
        "        self.attn = Attention(planes)\n",
        "        self.map = enc_sup(planes,upsample_factor)\n",
        "        if downsample == True:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        elif isinstance(downsample, nn.Module):\n",
        "            self.downsample = downsample\n",
        "        else:\n",
        "            self.downsample = None\n",
        "        self.stride = stride\n",
        " \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(identity)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.bn1(x1)\n",
        " \n",
        "        x2 = self.conv2(x1+identity)\n",
        "        x2 = self.bn2(x2)\n",
        "\n",
        "        # x3 = self.conv3(x2)\n",
        "        # x3 = self.bn3(x3)\n",
        " \n",
        "        # if self.downsample is not None:\n",
        "        #     identity = self.downsample(identity)\n",
        " \n",
        "        out = x1 + x2 + identity\n",
        "        out = self.relu(out)\n",
        "        out = self.attn(out)\n",
        "        out_map = self.map(out)\n",
        "        return out, out_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GZ31bJ76Tjq"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        " \n",
        "    def __init__(\n",
        "        self,\n",
        "        initial_channel: int, \n",
        "        block: Type[Union[BasicBlock]],\n",
        "        layers: List[int],\n",
        "        num_classes: int = 1000,\n",
        "        zero_init_residual: bool = False,\n",
        "        groups: int = 1,\n",
        "        width_per_group: int = 64,\n",
        "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        " \n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(initial_channel, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        " \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1, dilate=False,\n",
        "                                       dilation=[1,2], upsample_factor=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=1,\n",
        "                                       dilate=False, dilation=[3,4], upsample_factor=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
        "                                       dilate=False, dilation=[5,6], upsample_factor=4)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
        "                                       dilate=False, dilation=[7,8], upsample_factor=8)\n",
        " \n",
        "        self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.maxpool3=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.maxpool4=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        " \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        " \n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
        " \n",
        "    def _make_layer(self, block: Type[Union[BasicBlock]], planes: int, blocks: int,\n",
        "                    stride: int = 1, dilate: bool = False, dilation: list = [], upsample_factor:int=1,) -> nn.Sequential:\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        upsample_factor=upsample_factor\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample,\n",
        "                            dilation=dilation,upsample_factor=upsample_factor))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,stride=1,\n",
        "                                dilation=dilation,upsample_factor=upsample_factor))\n",
        " \n",
        "        return nn.Sequential(*layers)\n",
        " \n",
        "    def forward(self, x): \n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x1,x1_out = self.layer1(x)\n",
        "        x2,x2_out = self.layer2(self.maxpool1(x1))\n",
        "        x3,x3_out = self.layer3(self.maxpool2(x2))\n",
        "        x4,x4_out = self.layer4(self.maxpool3(x3))\n",
        "        x5 = self.maxpool4(x4)\n",
        " \n",
        "        return x1,x2,x3,x4,x5,x1_out,x2_out,x3_out,x4_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7ASdGZuh4RJ"
      },
      "outputs": [],
      "source": [
        "class attn_pyram(nn.Module):\n",
        "  def __init__(self,input_features):\n",
        "    super(attn_pyram,self).__init__()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=2)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=[3, 3], stride=3)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=[4, 4], stride=4)\n",
        "    self.pool4 = nn.MaxPool2d(kernel_size=[5, 5], stride=5)\n",
        "    self.conv = bn_conv2(4*input_features,input_features,6)\n",
        "  def forward(self,x):\n",
        "    in_channels, h, w = x.size(1), x.size(2), x.size(3)\n",
        "    \n",
        "    x1 = F.interpolate(self.pool1(x), size=(h, w), mode='bilinear', align_corners=True)\n",
        "    x1 = x*torch.sigmoid(x1)\n",
        "    x2 = F.interpolate(self.pool2(x), size=(h, w), mode='bilinear', align_corners=True)\n",
        "    x2 = x*torch.sigmoid(x2)\n",
        "    x3 = F.interpolate(self.pool3(x), size=(h, w), mode='bilinear', align_corners=True)\n",
        "    x3 = x*torch.sigmoid(x3)\n",
        "    x4 = F.interpolate(self.pool4(x), size=(h, w), mode='bilinear', align_corners=True)    \n",
        "    x4 = x*torch.sigmoid(x4)\n",
        "\n",
        "    x_out=torch.cat((x1,x2,x3,x4),1)\n",
        "    x_out=self.conv(x_out)\n",
        "    return x_out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw8Hfm346K_E"
      },
      "outputs": [],
      "source": [
        "class upconv_block(nn.Module):\n",
        "  def __init__(self,input_features,output_features):\n",
        "    super(upconv_block,self).__init__()\n",
        "    self.conv1=nn.ConvTranspose2d(input_features,output_features,kernel_size=2,stride=2)\n",
        "    self.attn=Attention(output_features)\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.attn(x)\n",
        "    return x  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHWbVMpCGh5H"
      },
      "outputs": [],
      "source": [
        "class decoder(nn.Module):\n",
        "    def __init__(self,input_channels,dilation):\n",
        "        super(decoder,self).__init__()\n",
        "        self.conv1=bn_conv(input_channels,input_channels//2,dilation)\n",
        "        self.conv2=bn_conv(input_channels//2,input_channels//4,dilation)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.conv2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqqehrmMHEWb"
      },
      "outputs": [],
      "source": [
        "class final_decoder(nn.Module):\n",
        "    def __init__(self,input_channels,dilation):\n",
        "        super(final_decoder,self).__init__()\n",
        "        self.conv1=bn_conv(input_channels,input_channels//2,dilation)\n",
        "        self.conv2=nn.Conv2d(input_channels//2,64,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv3=nn.Conv2d(64,2,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.conv2(x)\n",
        "        x=self.conv3(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqdZRQszHfQF"
      },
      "outputs": [],
      "source": [
        "class D2MSA(nn.Module):\n",
        "    def __init__(self,input_channels):\n",
        "        super(D2MSA,self).__init__()\n",
        "        self.encoder=ResNet(input_channels,BasicBlock,[1,1,1,1])\n",
        "        self.bn_conv0=attn_pyram(512)\n",
        "        \n",
        "        self.decoder1=decoder(1024,8)\n",
        "        self.decoder2=decoder(512,6)\n",
        "        self.decoder3=decoder(256,4)\n",
        "        self.decoder4=final_decoder(128,2)\n",
        "        \n",
        "        self.dec1=dec_sup(1024)\n",
        "        self.dec2=dec_sup(512)\n",
        "        self.dec3=dec_sup(256)\n",
        "           \n",
        "        self.upconv1=upconv_block(512,512)\n",
        "        self.upconv2=upconv_block(256,256)\n",
        "        self.upconv3=upconv_block(128,128)\n",
        "        self.upconv4=upconv_block(64,64)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        \n",
        "        x1,x2,x3,x4,x5,xe_1,xe_2,xe_3,xe_4=self.encoder(x)\n",
        "        \n",
        "        x5=self.bn_conv0(x5)        \n",
        "\n",
        "        x5=self.upconv1(x5)\n",
        "        x_4=self.decoder1(torch.cat((x5,x4),1))\n",
        "        xd_4=self.dec1(torch.cat((x5,x4),1))\n",
        "\n",
        "        x_4=self.upconv2(x_4)\n",
        "        x_3=self.decoder2(torch.cat((x_4,x3),1))\n",
        "        xd_3=self.dec2(torch.cat((x_4,x3),1))\n",
        "\n",
        "        x_3=self.upconv3(x_3)\n",
        "        x_2=self.decoder3(torch.cat((x_3,x2),1))\n",
        "        xd_2=self.dec3(torch.cat((x_3,x2),1))\n",
        "\n",
        "        x_2=self.upconv4(x_2)\n",
        "        x_out=self.decoder4(torch.cat((x_2,x1),1))\n",
        "        \n",
        "        return x_out, (xd_2,xd_3,xd_4), (xe_1,xe_2,xe_3,xe_4) \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOt0EraOR-eD"
      },
      "outputs": [],
      "source": [
        "model=D2MSA(3).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00xRAT7LDWVO"
      },
      "outputs": [],
      "source": [
        "class IoU(nn.Module):\n",
        "    def __init__(self, threshold=0.5):\n",
        "        super(IoU, self).__init__()\n",
        "        self.threshold = threshold\n",
        " \n",
        "    def forward(self, target, input):\n",
        "       \n",
        "        eps = 1e-10\n",
        "        input_ = (input > self.threshold).data.float()\n",
        "        target_ = (target > self.threshold).data.float()\n",
        " \n",
        "        intersection = torch.clamp(input_ * target_, 0, 1)\n",
        "        union = torch.clamp(input_ + target_, 0, 1)\n",
        " \n",
        "        if torch.mean(intersection).lt(eps):\n",
        "            return torch.Tensor([0., 0., 0.,0.0, 0.])\n",
        "        else:\n",
        "            acc = torch.mean((input_ == target_).data.float())\n",
        "            iou = torch.mean(intersection) / torch.mean(union)\n",
        "            recall = torch.mean(intersection) / torch.mean(target_)\n",
        "            precision = torch.mean(intersection) / torch.mean(input_)\n",
        "            f1=(2.*recall*precision)/(recall+precision)\n",
        "            return torch.Tensor([acc, recall, precision, f1, iou])\n",
        "iou=IoU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ8BN29_60O0"
      },
      "outputs": [],
      "source": [
        "class dice_bce_loss(nn.Module):\n",
        "    def __init__(self, batch=True):\n",
        "        super(dice_bce_loss, self).__init__()\n",
        "        self.batch = batch\n",
        "        self.bce_loss = nn.BCELoss()\n",
        " \n",
        "    def soft_dice_coeff(self, y_true, y_pred):\n",
        "        smooth = 1.0  # may change\n",
        "        if self.batch:\n",
        "            i = torch.sum(y_true)\n",
        "            j = torch.sum(y_pred)\n",
        "            intersection = torch.sum(y_true * y_pred)\n",
        "        else:\n",
        "            i = y_true.sum(1).sum(1).sum(1)\n",
        "            j = y_pred.sum(1).sum(1).sum(1)\n",
        "            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n",
        "        score = (2. * intersection + smooth) / (i + j + smooth)\n",
        "        # score = (intersection + smooth) / (i + j - intersection + smooth)#iou\n",
        "        return score.mean()\n",
        " \n",
        "    def soft_dice_loss(self, y_true, y_pred):\n",
        "        loss = 1 - self.soft_dice_coeff(y_true, y_pred)\n",
        "        return loss\n",
        " \n",
        "    def __call__(self, y_pred, y_true):\n",
        "        a = self.bce_loss(y_pred, y_true)\n",
        "        b = self.soft_dice_loss(y_true, y_pred)\n",
        "        return a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2-KJaaz7wvm"
      },
      "outputs": [],
      "source": [
        "def soft_loss_region(preds,label):\n",
        "  dice_loss=dice_bce_loss()\n",
        "  loss1=dice_loss(preds[0][:,0:1,:,:],label)\n",
        "  loss2=dice_loss(preds[1][:,0:1,:,:],label)\n",
        "  loss3=dice_loss(preds[2][:,0:1,:,:],label)\n",
        "  loss4=dice_loss(preds[3][:,0:1,:,:],label)\n",
        "  loss=loss1+loss2+loss3+loss4\n",
        "  return loss\n",
        "\n",
        "def soft_loss_bound(preds,label):\n",
        "  dice_loss=dice_bce_loss()\n",
        "  loss1=dice_loss(preds[0][:,1:2,:,:],label)\n",
        "  loss2=dice_loss(preds[1][:,1:2,:,:],label)\n",
        "  loss3=dice_loss(preds[2][:,1:2,:,:],label)\n",
        "  loss4=dice_loss(preds[3][:,1:2,:,:],label)\n",
        "  loss=loss1+loss2+loss3+loss4\n",
        "  return loss\n",
        "\n",
        "\n",
        "def hard_loss_region(pred1,preds,label):\n",
        "  dice_loss=dice_bce_loss()\n",
        "  b,c,h,w=label.shape\n",
        "  loss1=dice_loss(pred1[:,0:1,:,:],label)\n",
        "  label=torch.nn.functional.interpolate(label, size=(h//2,w//2), scale_factor=None, mode='nearest')\n",
        "  loss2=dice_loss(preds[0][:,0:1,:,:],label)\n",
        "  label=torch.nn.functional.interpolate(label, size=(h//4,w//4), scale_factor=None, mode='nearest')\n",
        "  loss3=dice_loss(preds[1][:,0:1,:,:],label)\n",
        "  label=torch.nn.functional.interpolate(label, size=(h//8,w//8), scale_factor=None, mode='nearest')\n",
        "  loss4=dice_loss(preds[2][:,0:1,:,:],label)\n",
        "  loss=loss1+loss2+loss3+loss4\n",
        "  return loss  \n",
        "\n",
        "def hard_loss_bound(pred1,preds,label):\n",
        "  dice_loss=dice_bce_loss()\n",
        "  b,c,h,w=label.shape\n",
        "  loss1=dice_loss(pred1[:,1:2,:,:],label)\n",
        "  label=torch.nn.functional.interpolate(label, size=(h//2,w//2), scale_factor=None, mode='nearest')\n",
        "  loss2=dice_loss(preds[0][:,1:2,:,:],label)\n",
        "  label=torch.nn.functional.interpolate(label, size=(h//4,w//4), scale_factor=None, mode='nearest')\n",
        "  loss3=dice_loss(preds[1][:,1:2,:,:],label)\n",
        "  label=torch.nn.functional.interpolate(label, size=(h//8,w//8), scale_factor=None, mode='nearest')\n",
        "  loss4=dice_loss(preds[2][:,1:2,:,:],label)\n",
        "  loss=loss1+loss2+loss3+loss4\n",
        "  return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSMR8HbQCf8y"
      },
      "outputs": [],
      "source": [
        "def loss_fn_region(pred1,preds_dec,preds_enc,label):\n",
        "  loss_enc=soft_loss_region(preds_enc,label)\n",
        "  loss_dec=hard_loss_region(pred1,preds_dec,label)\n",
        "  loss=loss_enc+loss_dec\n",
        "  return loss \n",
        "\n",
        "def loss_fn_bound(pred1,preds_dec,preds_enc,label):\n",
        "  loss_enc=soft_loss_bound(preds_enc,label)\n",
        "  loss_dec=hard_loss_bound(pred1,preds_dec,label)\n",
        "  loss=loss_enc+loss_dec\n",
        "  return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HTBqvSEs8E5"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model,train_dl,learn):\n",
        "  opt = torch.optim.Adam(model.parameters(),lr=learn)  \n",
        "  running_loss_image=0.0\n",
        "  metric_epoch=0.0\n",
        "  model.train()\n",
        "  for a,b in train_dl:\n",
        "    a=a.float()\n",
        "    b=b.float()\n",
        "    pred1,preds_dec,preds_enc=model(a.cuda())\n",
        "    loss=loss_fn_region(pred1,preds_dec,preds_enc,b[:,0:1,:,:].cuda()) + loss_fn_bound(pred1,preds_dec,preds_enc,b[:,1:2,:,:].cuda())\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    running_loss_image += loss\n",
        "    metric=iou(b[:,0:1,:,:],pred1[:,0:1,:,:].detach().cpu())\n",
        "    metric_epoch += metric\n",
        "  running_loss_image/=len(train_dl)\n",
        "  metric_epoch /= len(train_dl)  \n",
        "  \n",
        "  return model, metric_epoch, running_loss_image\n",
        "\n",
        "def validate_one_epoch(model,test_dl):\n",
        "    running_loss_image=0.0\n",
        "    metric_epoch=0.0\n",
        "    model.train()\n",
        "    with torch.no_grad():\n",
        "      for a,b in test_dl:\n",
        "        a=a.float()\n",
        "        b=b.float()\n",
        "        pred1,preds_dec,preds_enc=model(a.cuda())\n",
        "        loss=loss_fn_region(pred1,preds_dec,preds_enc,b[:,0:1,:,:].cuda()) + loss_fn_bound(pred1,preds_dec,preds_enc,b[:,1:2,:,:].cuda())\n",
        "        running_loss_image += loss\n",
        "        metric=iou(b[:,0:1,:,:],pred1[:,0:1,:,:].detach().cpu())\n",
        "        metric_epoch += metric  \n",
        "    running_loss_image/=len(test_dl)\n",
        "    metric_epoch /= len(test_dl)\n",
        "\n",
        "    return metric_epoch, running_loss_image        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "374sQZYTvDGN"
      },
      "outputs": [],
      "source": [
        "def train_epochs_net(model,train_dl,test_dl,epoches,learn,path):\n",
        "    max_accuracy=0.0\n",
        "    for i in range(epoches):  \n",
        "        model, iou_train, loss_train=train_one_epoch(model,train_dl,learn)\n",
        "        iou_test, loss_test=validate_one_epoch(model,test_dl)\n",
        "        print('epoch finished' +\" \" + str(i+1))\n",
        "        print(f'train_loss: {loss_train:.6f}, train_iou: {iou_train[4]:.6f}')\n",
        "        print(f'test_loss: {loss_test:.6f}, test_iou: {iou_test[4]:.6f}')\n",
        "        print()\n",
        "        if iou_test[4]>max_accuracy:\n",
        "            max_accuracy=iou_test[4]\n",
        "            path_final=os.path.join(path,\n",
        "                                    f\"epoch{i}_test_iou{iou_test[4]:.4f}\")\n",
        "            torch.save(model.state_dict(), path_final)    \n",
        "        # path_final=os.path.join(path,\n",
        "        #                             f\"epoch{i}_test_loss{loss_test:.4f}.pth\")\n",
        "        # torch.save(model.state_dict(), path_final)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fast_aji(true, pred):\n",
        "    \"\"\"AJI version distributed by MoNuSeg, has no permutation problem but suffered from \n",
        "    over-penalisation similar to DICE2.\n",
        "    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4] \n",
        "    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no \n",
        "    effect on the result.\n",
        "    \"\"\"\n",
        "    true = np.copy(true)  # ? do we need this\n",
        "    pred = np.copy(pred)\n",
        "    true_id_list = list(np.unique(true))\n",
        "    pred_id_list = list(np.unique(pred))\n",
        "\n",
        "    true_masks = [\n",
        "        None,\n",
        "    ]\n",
        "    for t in true_id_list[1:]:\n",
        "        t_mask = np.array(true == t, np.uint8)\n",
        "        true_masks.append(t_mask)\n",
        "\n",
        "    pred_masks = [\n",
        "        None,\n",
        "    ]\n",
        "    for p in pred_id_list[1:]:\n",
        "        p_mask = np.array(pred == p, np.uint8)\n",
        "        pred_masks.append(p_mask)\n",
        "\n",
        "    # prefill with value\n",
        "    pairwise_inter = np.zeros(\n",
        "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
        "    )\n",
        "    pairwise_union = np.zeros(\n",
        "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
        "    )\n",
        "\n",
        "    # caching pairwise\n",
        "    for true_id in true_id_list[1:]:  # 0-th is background\n",
        "        t_mask = true_masks[true_id]\n",
        "        pred_true_overlap = pred[t_mask > 0]\n",
        "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
        "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
        "        for pred_id in pred_true_overlap_id:\n",
        "            if pred_id == 0:  # ignore\n",
        "                continue  # overlaping background\n",
        "            p_mask = pred_masks[pred_id]\n",
        "            total = (t_mask + p_mask).sum()\n",
        "            inter = (t_mask * p_mask).sum()\n",
        "            pairwise_inter[true_id - 1, pred_id - 1] = inter\n",
        "            pairwise_union[true_id - 1, pred_id - 1] = total - inter\n",
        "\n",
        "    pairwise_iou = pairwise_inter / (pairwise_union + 1.0e-6)\n",
        "    # pair of pred that give highest iou for each true, dont care\n",
        "    # about reusing pred instance multiple times\n",
        "    paired_pred = np.argmax(pairwise_iou, axis=1)\n",
        "    pairwise_iou = np.max(pairwise_iou, axis=1)\n",
        "    # exlude those dont have intersection\n",
        "    paired_true = np.nonzero(pairwise_iou > 0.0)[0]\n",
        "    paired_pred = paired_pred[paired_true]\n",
        "    # print(paired_true.shape, paired_pred.shape)\n",
        "    overall_inter = (pairwise_inter[paired_true, paired_pred]).sum()\n",
        "    overall_union = (pairwise_union[paired_true, paired_pred]).sum()\n",
        "\n",
        "    paired_true = list(paired_true + 1)  # index to instance ID\n",
        "    paired_pred = list(paired_pred + 1)\n",
        "    # add all unpaired GT and Prediction into the union\n",
        "    unpaired_true = np.array(\n",
        "        [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
        "    )\n",
        "    unpaired_pred = np.array(\n",
        "        [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
        "    )\n",
        "    for true_id in unpaired_true:\n",
        "        overall_union += true_masks[true_id].sum()\n",
        "    for pred_id in unpaired_pred:\n",
        "        overall_union += pred_masks[pred_id].sum()\n",
        "\n",
        "    aji_score = overall_inter / overall_union\n",
        "    return aji_score\n"
      ],
      "metadata": {
        "id": "kUbA611nUcQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fast_dice_2(true, pred):\n",
        "    \"\"\"Ensemble dice.\"\"\"\n",
        "    true = np.copy(true)\n",
        "    pred = np.copy(pred)\n",
        "    true_id = list(np.unique(true))\n",
        "    pred_id = list(np.unique(pred))\n",
        "\n",
        "    overall_total = 0\n",
        "    overall_inter = 0\n",
        "\n",
        "    true_masks = [np.zeros(true.shape)]\n",
        "    for t in true_id[1:]:\n",
        "        t_mask = np.array(true == t, np.uint8)\n",
        "        true_masks.append(t_mask)\n",
        "\n",
        "    pred_masks = [np.zeros(true.shape)]\n",
        "    for p in pred_id[1:]:\n",
        "        p_mask = np.array(pred == p, np.uint8)\n",
        "        pred_masks.append(p_mask)\n",
        "\n",
        "    for true_idx in range(1, len(true_id)):\n",
        "        t_mask = true_masks[true_idx]\n",
        "        pred_true_overlap = pred[t_mask > 0]\n",
        "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
        "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
        "        try:  # blinly remove background\n",
        "            pred_true_overlap_id.remove(0)\n",
        "        except ValueError:\n",
        "            pass  # just mean no background\n",
        "        for pred_idx in pred_true_overlap_id:\n",
        "            p_mask = pred_masks[pred_idx]\n",
        "            total = (t_mask + p_mask).sum()\n",
        "            inter = (t_mask * p_mask).sum()\n",
        "            overall_total += total\n",
        "            overall_inter += inter\n",
        "\n",
        "    return 2 * overall_inter / overall_total\n"
      ],
      "metadata": {
        "id": "1xnPLcmFUcz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model,test_dl):\n",
        "  model.eval()\n",
        "  aji_score=0.0\n",
        "  dice_score=0.0\n",
        "  with torch.no_grad():\n",
        "    for a,b in test_dl:\n",
        "      aji_batch=0.0\n",
        "      dice_batch=0.0\n",
        "      a=a.float()\n",
        "      b=b.float()\n",
        "      pred1,_,_=model(a.cuda())\n",
        "      pred1=pred1.detach().cpu().numpy()\n",
        "      b=b.detach().cpu().numpy()\n",
        "      for i in range(pred1.shape[0]):\n",
        "        pred=(pred1[i,0,:,:]>0.5)*1.0\n",
        "        gt_label=skimage.morphology.label(b[i,0,:,:], return_num=False)\n",
        "        pred_label=skimage.morphology.label(pred, return_num=False)\n",
        "        aji=get_fast_aji(gt_label,pred_label)\n",
        "        dice_obj=get_fast_dice_2(gt_label,pred_label)\n",
        "        aji_batch += aji\n",
        "        dice_batch += dice_obj\n",
        "      aji_batch=aji_batch/(pred1.shape[0])\n",
        "      dice_batch=dice_batch/(pred1.shape[0])\n",
        "      aji_score += aji_batch\n",
        "      dice_score += dice_batch\n",
        "  aji_score /= len(test_dl)\n",
        "  dice_score /= len(test_dl)\n",
        "  return aji_score, dice_score  "
      ],
      "metadata": {
        "id": "1OcnobbVUCBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aj,di=evaluation(model,test_dl)"
      ],
      "metadata": {
        "id": "H3fIhEnZUTAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fast_pq(true, pred, match_iou=0.5):\n",
        "    \"\"\"`match_iou` is the IoU threshold level to determine the pairing between\n",
        "    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n",
        "    if IoU > `match_iou`. However, pair of `p` and `g` must be unique \n",
        "    (1 prediction instance to 1 GT instance mapping).\n",
        "    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n",
        "    in bipartite graphs) is caculated to find the maximal amount of unique pairing. \n",
        "    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n",
        "    the number of pairs is also maximal.    \n",
        "    \n",
        "    Fast computation requires instance IDs are in contiguous orderding \n",
        "    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand \n",
        "    and `by_size` flag has no effect on the result.\n",
        "    Returns:\n",
        "        [dq, sq, pq]: measurement statistic\n",
        "        [paired_true, paired_pred, unpaired_true, unpaired_pred]: \n",
        "                      pairing information to perform measurement\n",
        "                    \n",
        "    \"\"\"\n",
        "    assert match_iou >= 0.0, \"Cant' be negative\"\n",
        "\n",
        "    true = np.copy(true)\n",
        "    pred = np.copy(pred)\n",
        "    true_id_list = list(np.unique(true))\n",
        "    pred_id_list = list(np.unique(pred))\n",
        "\n",
        "    true_masks = [\n",
        "        None,\n",
        "    ]\n",
        "    for t in true_id_list[1:]:\n",
        "        t_mask = np.array(true == t, np.uint8)\n",
        "        true_masks.append(t_mask)\n",
        "\n",
        "    pred_masks = [\n",
        "        None,\n",
        "    ]\n",
        "    for p in pred_id_list[1:]:\n",
        "        p_mask = np.array(pred == p, np.uint8)\n",
        "        pred_masks.append(p_mask)\n",
        "\n",
        "    # prefill with value\n",
        "    pairwise_iou = np.zeros(\n",
        "        [len(true_id_list) - 1, len(pred_id_list) - 1], dtype=np.float64\n",
        "    )\n",
        "\n",
        "    # caching pairwise iou\n",
        "    for true_id in true_id_list[1:]:  # 0-th is background\n",
        "        t_mask = true_masks[true_id]\n",
        "        pred_true_overlap = pred[t_mask > 0]\n",
        "        pred_true_overlap_id = np.unique(pred_true_overlap)\n",
        "        pred_true_overlap_id = list(pred_true_overlap_id)\n",
        "        for pred_id in pred_true_overlap_id:\n",
        "            if pred_id == 0:  # ignore\n",
        "                continue  # overlaping background\n",
        "            p_mask = pred_masks[pred_id]\n",
        "            total = (t_mask + p_mask).sum()\n",
        "            inter = (t_mask * p_mask).sum()\n",
        "            iou = inter / (total - inter)\n",
        "            pairwise_iou[true_id - 1, pred_id - 1] = iou\n",
        "    #\n",
        "    if match_iou >= 0.5:\n",
        "        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n",
        "        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n",
        "        paired_true, paired_pred = np.nonzero(pairwise_iou)\n",
        "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
        "        paired_true += 1  # index is instance id - 1\n",
        "        paired_pred += 1  # hence return back to original\n",
        "    else:  # * Exhaustive maximal unique pairing\n",
        "        #### Munkres pairing with scipy library\n",
        "        # the algorithm return (row indices, matched column indices)\n",
        "        # if there is multiple same cost in a row, index of first occurence\n",
        "        # is return, thus the unique pairing is ensure\n",
        "        # inverse pair to get high IoU as minimum\n",
        "        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n",
        "        ### extract the paired cost and remove invalid pair\n",
        "        paired_iou = pairwise_iou[paired_true, paired_pred]\n",
        "\n",
        "        # now select those above threshold level\n",
        "        # paired with iou = 0.0 i.e no intersection => FP or FN\n",
        "        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n",
        "        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n",
        "        paired_iou = paired_iou[paired_iou > match_iou]\n",
        "\n",
        "    # get the actual FP and FN\n",
        "    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n",
        "    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n",
        "    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n",
        "\n",
        "    #\n",
        "    tp = len(paired_true)\n",
        "    fp = len(unpaired_pred)\n",
        "    fn = len(unpaired_true)\n",
        "    # get the F1-score i.e DQ\n",
        "    dq = tp / (tp + 0.5 * fp + 0.5 * fn)\n",
        "    # get the SQ, no paired has 0 iou so not impact\n",
        "    sq = paired_iou.sum() / (tp + 1.0e-6)\n",
        "\n",
        "    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]\n"
      ],
      "metadata": {
        "id": "L79LnDaabjXD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}